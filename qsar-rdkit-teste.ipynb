{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Advanced in silico drug design workshop. Olomouc, 30 January - 1 February, 2017.\n",
    "### QSAR tutorial.\n",
    "Dr. Pavel Polishchuk  \n",
    "   \n",
    "Institute of Molecular and Translational Medicine, Faculty of Medicine and Dentistry, Palacký University and University Hospital in Olomouc, Hněvotínská 1333/5, 779 00 Olomouc, Czech Republic  \n",
    "http://imtm.cz  \n",
    "http://qsar4u.com  \n",
    "pavel_polishchuk@ukr.net  \n",
    "pavlo.polishchuk@upol.cz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named rdkit",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-20552e3f76e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mChem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataStructs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mrdkit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAllChem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDescriptors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named rdkit"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem, Descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from rdkit.Chem.Draw import IPythonConsole\n",
    "# from rdkit.Chem import Draw\n",
    "# IPythonConsole.ipython_useSVG=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, cohen_kappa_score, matthews_corrcoef\n",
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading molecules and activity from SDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fname = \"data/logBB.sdf\"\n",
    "\n",
    "mols = []\n",
    "y = []\n",
    "for mol in Chem.SDMolSupplier(fname):\n",
    "    if mol is not None:\n",
    "        mols.append(mol)\n",
    "        y.append(mol.GetIntProp(\"logBB_class\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate descriptors (fingerprints) and convert them into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate binary Morgan fingerprint with radius 2\n",
    "fp = [AllChem.GetMorganFingerprintAsBitVect(m, 2) for m in mols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rdkit_numpy_convert(fp):\n",
    "    output = []\n",
    "    for f in fp:\n",
    "        arr = np.zeros((1,))\n",
    "        DataStructs.ConvertToNumpyArray(f, arr)\n",
    "        output.append(arr)\n",
    "    return np.asarray(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x = rdkit_numpy_convert(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check wether the data set is balanced\n",
    "sum(y) / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set random seed to make all further calculations reproducible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the whole set on training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly select 20% of compounds as test set\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create folds for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print out ids of folds\n",
    "for i, (train_index, test_index) in enumerate(cv.split(x_tr, y_tr)):\n",
    "    print(\"\\nFold_\" + str(i+1))\n",
    "    print(\"TRAIN:\", train_index)\n",
    "    print(\"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scale X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step may be crucial for certain modeling approaches lke SVM.\n",
    "In the case of binary fingerprints it may be less useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# obtain scale object which can be further applied to scale any data to fit the training set\n",
    "scale = StandardScaler().fit(x_tr)\n",
    "x_tr = scale.transform(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# it is a good idea to save it for future use\n",
    "joblib.dump(scale, \"data/logBB_scale.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search for optimal tuning parameters and build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create grid search dictionary\n",
    "param_grid = {\"max_features\": [x_tr.shape[1] // 10, x_tr.shape[1] // 7, x_tr.shape[1] // 5, x_tr.shape[1] // 3], \n",
    "              \"n_estimators\": [100, 250, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup model building\n",
    "m = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run model building\n",
    "m.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.cv_results_['params']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(m, \"data/logBB_rf_morgan.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Predict test set compounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load scale if necessary\n",
    "scale = joblib.load(\"data/logBB_scale.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale descriptors of the test set compounds\n",
    "x_ts = scale.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict logBB class\n",
    "pred_rf = m.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calc statistics for test set preditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_ts, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matthews_corrcoef(y_ts, pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohen_kappa_score(y_ts, pred_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### applicability domain estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# if the model includes several ones like RF models or consensus models (or for probabilistic models)\n",
    "# we can calculate consistency of predictions amongs those models and use it for estimation of applicability domain\n",
    "pred_prob = m.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# probablity\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup threshold\n",
    "threshold = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc maximum predicted probability for each row (compound) and compare to the threshold\n",
    "da = np.amax(pred_prob, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc statistics\n",
    "accuracy_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "matthews_corrcoef(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cohen_kappa_score(np.asarray(y_ts)[da], pred_rf[da])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc coverage\n",
    "sum(da) / len(da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create grid search dictionary\n",
    "param_grid = {\"C\": [10 ** i for i in range(0, 5)],\n",
    "              \"gamma\": [10 ** i for i in range(-6, 0)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup model building\n",
    "svm = GridSearchCV(SVC(kernel='rbf', probability=True), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run model building\n",
    "svm.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save model\n",
    "joblib.dump(svm, \"data/logBB_svm_morgan.pkl\", compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict logBB for the test set compounds\n",
    "pred_svm = svm.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred_svm))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_svm))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimate applicability domain and calc stat\n",
    "pred_prob = svm.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da = np.amax(pred_prob, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy = \", accuracy_score(np.asarray(y_ts)[da], pred_svm[da]))\n",
    "print(\"MCC = \", matthews_corrcoef(np.asarray(y_ts)[da], pred_svm[da]))\n",
    "print(\"Kappa = \", cohen_kappa_score(np.asarray(y_ts)[da], pred_svm[da]))\n",
    "print(\"Coverage = \", sum(da) / len(da))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### build the third model (GBM) compute consensus predictions from RF, and SVM models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# setup model building\n",
    "param_grid = {\"n_estimators\": [100, 200, 300, 400, 500]}\n",
    "gbm = GridSearchCV(GradientBoostingClassifier(subsample=0.5, max_features=0.5), \n",
    "                   param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run model building\n",
    "gbm.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gbm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_gbm = gbm.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred_gbm))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_gbm))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_gbm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### consensus model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_c = 1 * (((pred_rf + pred_svm + pred_gbm) / 3) >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred_c))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred_c))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred_c))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Add to Morgan fingerprints some other descriptors and look at the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc some descriptors\n",
    "descr = []\n",
    "for m in mols:\n",
    "    descr.append([Descriptors.MolLogP(m),\n",
    "                  Descriptors.TPSA(m),\n",
    "                  Descriptors.NHOHCount(m),\n",
    "                  Descriptors.NOCount(m),\n",
    "                  Descriptors.NumHAcceptors(m),\n",
    "                  Descriptors.NumHDonors(m),\n",
    "                  Descriptors.NumRotatableBonds(m),\n",
    "                  Descriptors.NumHeteroatoms(m),\n",
    "                  Descriptors.FractionCSP3(m)])\n",
    "descr = np.asarray(descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "descr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add them to morgan fingerprints\n",
    "x = np.concatenate((x, descr), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# randomly select 20% of compounds as test set\n",
    "x_tr, x_ts, y_tr, y_ts = train_test_split(x, y, test_size=0.20, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scale = StandardScaler().fit(x_tr)\n",
    "x_tr = scale.transform(x_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create grid search dictionary\n",
    "param_grid = {\"max_features\": [x_tr.shape[1] // 10, x_tr.shape[1] // 7, x_tr.shape[1] // 5, x_tr.shape[1] // 3], \n",
    "              \"n_estimators\": [100, 250, 500]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# setup model building\n",
    "m = GridSearchCV(RandomForestClassifier(), param_grid, n_jobs=2, cv=cv, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# run model building\n",
    "m.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale descriptors of the test set compounds\n",
    "x_ts = scale.transform(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict logBB for the test set compounds\n",
    "pred = m.predict(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calc statistics\n",
    "print(\"Accuracy = \", accuracy_score(y_ts, pred))\n",
    "print(\"MCC = \", matthews_corrcoef(y_ts, pred))\n",
    "print(\"Kappa = \", cohen_kappa_score(y_ts, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# estimate applicability domain and calc stat\n",
    "pred_prob = m.predict_proba(x_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "da = np.amax(pred_prob, axis=1) > threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"Accuracy = \", accuracy_score(np.asarray(y_ts)[da], pred[da]))\n",
    "print(\"MCC = \", matthews_corrcoef(np.asarray(y_ts)[da], pred[da]))\n",
    "print(\"Kappa = \", cohen_kappa_score(np.asarray(y_ts)[da], pred[da]))\n",
    "print(\"Coverage = \", sum(da) / len(da))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model has a better accuracy. Added descritors improved the model predictivity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Let's try to analyse which variables are the most important in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# rebuild RF model manually using best parameters to be able to extract additional information from the model\n",
    "rf = RandomForestClassifier(n_estimators=m.best_params_[\"n_estimators\"], \n",
    "                           max_features=m.best_params_[\"max_features\"],\n",
    "                           random_state=seed)\n",
    "rf.fit(x_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp = rf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices = np.argsort(imp)[::-1]\n",
    "\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "# print top 10 features\n",
    "for i in range(10):\n",
    "    print(\"%d. feature %d (%f)\" % (i + 1, indices[i], imp[indices[i]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2049 - MolLogP  \n",
    "2050 - TPSA(m)  \n",
    "2051 - NHOHCount  \n",
    "2052 - NOCount \n",
    "2053 - NumHAcceptors  \n",
    "2054 - NumHDonors  \n",
    "2055 - NumRotatableBonds  \n",
    "2056 - NumHeteroatoms  \n",
    "2057 - FractionCSP3\n",
    "\n",
    "features with numbers 1-2048 are different Morgan fingerprints  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
